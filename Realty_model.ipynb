{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PjNO-592JEGu"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MvQA9knPKpui",
        "outputId": "e6fbfe90-aece-4f7a-e13e-a25b31e12d2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>offer_id</th>\n",
              "      <th>price</th>\n",
              "      <th>date_time</th>\n",
              "      <th>room</th>\n",
              "      <th>square</th>\n",
              "      <th>floor</th>\n",
              "      <th>all_floors</th>\n",
              "      <th>firstlast</th>\n",
              "      <th>district</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3740338125</td>\n",
              "      <td>3420000</td>\n",
              "      <td>2024-07-17 17:48:14</td>\n",
              "      <td>0</td>\n",
              "      <td>24.3</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3988744322</td>\n",
              "      <td>10500000</td>\n",
              "      <td>2024-08-05 14:54:43</td>\n",
              "      <td>2</td>\n",
              "      <td>63.0</td>\n",
              "      <td>7</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4216500542</td>\n",
              "      <td>5000000</td>\n",
              "      <td>2024-08-09 09:09:30</td>\n",
              "      <td>2</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4054056420</td>\n",
              "      <td>3600000</td>\n",
              "      <td>2024-08-06 07:29:07</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4128038144</td>\n",
              "      <td>5950000</td>\n",
              "      <td>2024-08-09 00:37:58</td>\n",
              "      <td>3</td>\n",
              "      <td>59.0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     offer_id     price            date_time  room  square  floor  all_floors  \\\n",
              "0  3740338125   3420000  2024-07-17 17:48:14     0    24.3     17          18   \n",
              "1  3988744322  10500000  2024-08-05 14:54:43     2    63.0      7          25   \n",
              "2  4216500542   5000000  2024-08-09 09:09:30     2    45.0      2           5   \n",
              "3  4054056420   3600000  2024-08-06 07:29:07     0    28.0     15          16   \n",
              "4  4128038144   5950000  2024-08-09 00:37:58     3    59.0      4           5   \n",
              "\n",
              "   firstlast  district  \n",
              "0          0         8  \n",
              "1          0         3  \n",
              "2          0         3  \n",
              "3          0         8  \n",
              "4          0         8  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('realty_dataset.csv', sep=';')\n",
        "df.rename(columns={'first/last': 'firstlast'}, inplace=True)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uhSv5nUeK9W5",
        "outputId": "efbefe0f-bec9-42c3-d721-5a6741d6d9e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([24.3])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.array(df.square)\n",
        "y = np.array(df.price)\n",
        "display(x[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Ork_bOlDJUQO",
        "outputId": "48bbcf10-618e-423d-8899-857122076686"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Py_project\\realty\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">609</span> (2.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m609\u001b[0m (2.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">609</span> (2.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m609\u001b[0m (2.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_shape=(1,)))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cU45Yb0qJcyv"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6gw6jPGJh2H",
        "outputId": "06b17f34-7bd3-4404-9664-066ebdba7333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5142267035648.0000 - mae: 1497644.0000 - val_loss: 8029702979584.0000 - val_mae: 1863557.1250\n",
            "Epoch 2/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8479280988160.0000 - mae: 1810416.5000 - val_loss: 8028837380096.0000 - val_mae: 1863455.3750\n",
            "Epoch 3/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8935791656960.0000 - mae: 1711977.3750 - val_loss: 8029646356480.0000 - val_mae: 1863560.5000\n",
            "Epoch 4/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6702391361536.0000 - mae: 1592402.5000 - val_loss: 8027821309952.0000 - val_mae: 1863338.8750\n",
            "Epoch 5/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7801658146816.0000 - mae: 1688059.2500 - val_loss: 8028465659904.0000 - val_mae: 1863424.6250\n",
            "Epoch 6/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6771683885056.0000 - mae: 1621190.6250 - val_loss: 8026933690368.0000 - val_mae: 1863238.3750\n",
            "Epoch 7/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7454777671680.0000 - mae: 1651393.3750 - val_loss: 8026191822848.0000 - val_mae: 1863150.2500\n",
            "Epoch 8/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7631456436224.0000 - mae: 1678183.8750 - val_loss: 8025535938560.0000 - val_mae: 1863072.1250\n",
            "Epoch 9/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9370855276544.0000 - mae: 1801876.0000 - val_loss: 8025204064256.0000 - val_mae: 1863035.0000\n",
            "Epoch 10/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8176655663104.0000 - mae: 1598569.7500 - val_loss: 8025836355584.0000 - val_mae: 1863121.2500\n",
            "Epoch 11/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6244712054784.0000 - mae: 1488091.7500 - val_loss: 8024827101184.0000 - val_mae: 1862998.2500\n",
            "Epoch 12/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5669478989824.0000 - mae: 1471061.0000 - val_loss: 8024496799744.0000 - val_mae: 1862962.1250\n",
            "Epoch 13/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6602430087168.0000 - mae: 1607809.3750 - val_loss: 8026499055616.0000 - val_mae: 1863221.0000\n",
            "Epoch 14/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7218368348160.0000 - mae: 1557542.8750 - val_loss: 8024650940416.0000 - val_mae: 1862993.3750\n",
            "Epoch 15/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9593024413696.0000 - mae: 1717655.1250 - val_loss: 8026729742336.0000 - val_mae: 1863260.0000\n",
            "Epoch 16/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6636292800512.0000 - mae: 1542010.0000 - val_loss: 8026867630080.0000 - val_mae: 1863282.7500\n",
            "Epoch 17/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7416883707904.0000 - mae: 1599228.3750 - val_loss: 8027118764032.0000 - val_mae: 1863319.2500\n",
            "Epoch 18/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6862352154624.0000 - mae: 1574370.5000 - val_loss: 8026062323712.0000 - val_mae: 1863192.8750\n",
            "Epoch 19/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10837125234688.0000 - mae: 1879951.7500 - val_loss: 8026754383872.0000 - val_mae: 1863284.1250\n",
            "Epoch 20/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6605068828672.0000 - mae: 1509971.1250 - val_loss: 8026517929984.0000 - val_mae: 1863259.1250\n",
            "Epoch 21/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7530644766720.0000 - mae: 1679204.2500 - val_loss: 8024456429568.0000 - val_mae: 1863007.7500\n",
            "Epoch 22/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6053313380352.0000 - mae: 1549778.3750 - val_loss: 8025338281984.0000 - val_mae: 1863123.0000\n",
            "Epoch 23/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8999419248640.0000 - mae: 1688305.3750 - val_loss: 8025166315520.0000 - val_mae: 1863106.8750\n",
            "Epoch 24/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8629903687680.0000 - mae: 1703647.5000 - val_loss: 8026223804416.0000 - val_mae: 1863243.0000\n",
            "Epoch 25/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 9887214993408.0000 - mae: 1728243.2500 - val_loss: 8024310153216.0000 - val_mae: 1863010.1250\n",
            "Epoch 26/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6067043958784.0000 - mae: 1518338.7500 - val_loss: 8024603754496.0000 - val_mae: 1863052.5000\n",
            "Epoch 27/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5958462341120.0000 - mae: 1517274.0000 - val_loss: 8022243934208.0000 - val_mae: 1862759.3750\n",
            "Epoch 28/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7090319392768.0000 - mae: 1658180.8750 - val_loss: 8022088744960.0000 - val_mae: 1862745.0000\n",
            "Epoch 29/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6249662382080.0000 - mae: 1585998.2500 - val_loss: 8019662340096.0000 - val_mae: 1862434.8750\n",
            "Epoch 30/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6330282147840.0000 - mae: 1503272.1250 - val_loss: 8023001530368.0000 - val_mae: 1862872.6250\n",
            "Epoch 31/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7180688293888.0000 - mae: 1724087.7500 - val_loss: 8020633845760.0000 - val_mae: 1862574.2500\n",
            "Epoch 32/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6223563325440.0000 - mae: 1608258.5000 - val_loss: 8022138028032.0000 - val_mae: 1862774.2500\n",
            "Epoch 33/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7569385979904.0000 - mae: 1681989.0000 - val_loss: 8021496823808.0000 - val_mae: 1862698.0000\n",
            "Epoch 34/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5864898428928.0000 - mae: 1573240.3750 - val_loss: 8021484765184.0000 - val_mae: 1862701.8750\n",
            "Epoch 35/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6732172492800.0000 - mae: 1658692.2500 - val_loss: 8019824869376.0000 - val_mae: 1862494.0000\n",
            "Epoch 36/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6743264854016.0000 - mae: 1648023.7500 - val_loss: 8020441432064.0000 - val_mae: 1862580.1250\n",
            "Epoch 37/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9172695384064.0000 - mae: 1751109.2500 - val_loss: 8022298460160.0000 - val_mae: 1862822.3750\n",
            "Epoch 38/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7257441959936.0000 - mae: 1605099.2500 - val_loss: 8019950698496.0000 - val_mae: 1862528.0000\n",
            "Epoch 39/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7043016556544.0000 - mae: 1713001.0000 - val_loss: 8020805287936.0000 - val_mae: 1862643.8750\n",
            "Epoch 40/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10181171740672.0000 - mae: 1630269.1250 - val_loss: 8020459257856.0000 - val_mae: 1862605.2500\n",
            "Epoch 41/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5749900050432.0000 - mae: 1531659.1250 - val_loss: 8017238032384.0000 - val_mae: 1862190.1250\n",
            "Epoch 42/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8894645534720.0000 - mae: 1772831.1250 - val_loss: 8020694663168.0000 - val_mae: 1862646.3750\n",
            "Epoch 43/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7521076510720.0000 - mae: 1670029.1250 - val_loss: 8020800569344.0000 - val_mae: 1862665.5000\n",
            "Epoch 44/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7320511709184.0000 - mae: 1605263.1250 - val_loss: 8021559214080.0000 - val_mae: 1862766.1250\n",
            "Epoch 45/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7956621950976.0000 - mae: 1640950.0000 - val_loss: 8022222962688.0000 - val_mae: 1862854.1250\n",
            "Epoch 46/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10087016955904.0000 - mae: 1803009.3750 - val_loss: 8022116007936.0000 - val_mae: 1862846.2500\n",
            "Epoch 47/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8512020676608.0000 - mae: 1715371.2500 - val_loss: 8022249177088.0000 - val_mae: 1862866.5000\n",
            "Epoch 48/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10763509956608.0000 - mae: 1817790.7500 - val_loss: 8021783609344.0000 - val_mae: 1862813.3750\n",
            "Epoch 49/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7068105310208.0000 - mae: 1662889.6250 - val_loss: 8025287950336.0000 - val_mae: 1863242.2500\n",
            "Epoch 50/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6044072804352.0000 - mae: 1587906.2500 - val_loss: 8019304251392.0000 - val_mae: 1862511.8750\n",
            "Epoch 51/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7763330072576.0000 - mae: 1665393.1250 - val_loss: 8018160254976.0000 - val_mae: 1862371.3750\n",
            "Epoch 52/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 14014284300288.0000 - mae: 2000839.6250 - val_loss: 8020214415360.0000 - val_mae: 1862638.3750\n",
            "Epoch 53/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6528558432256.0000 - mae: 1562535.5000 - val_loss: 8020465549312.0000 - val_mae: 1862675.1250\n",
            "Epoch 54/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6222558789632.0000 - mae: 1615166.2500 - val_loss: 8016400744448.0000 - val_mae: 1862160.2500\n",
            "Epoch 55/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7827717881856.0000 - mae: 1736128.7500 - val_loss: 8019670728704.0000 - val_mae: 1862585.7500\n",
            "Epoch 56/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8038100500480.0000 - mae: 1707047.2500 - val_loss: 8020082819072.0000 - val_mae: 1862642.5000\n",
            "Epoch 57/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8157955358720.0000 - mae: 1758641.8750 - val_loss: 8019686981632.0000 - val_mae: 1862598.0000\n",
            "Epoch 58/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7406974140416.0000 - mae: 1658906.7500 - val_loss: 8019740983296.0000 - val_mae: 1862609.7500\n",
            "Epoch 59/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7334817431552.0000 - mae: 1554259.6250 - val_loss: 8020109557760.0000 - val_mae: 1862661.0000\n",
            "Epoch 60/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6585861537792.0000 - mae: 1474201.7500 - val_loss: 8019726827520.0000 - val_mae: 1862617.5000\n",
            "Epoch 61/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7468662915072.0000 - mae: 1604074.3750 - val_loss: 8019187859456.0000 - val_mae: 1862556.0000\n",
            "Epoch 62/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5579391107072.0000 - mae: 1533672.0000 - val_loss: 8018586501120.0000 - val_mae: 1862485.7500\n",
            "Epoch 63/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7945275834368.0000 - mae: 1713065.2500 - val_loss: 8019765624832.0000 - val_mae: 1862637.7500\n",
            "Epoch 64/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8215190831104.0000 - mae: 1616088.5000 - val_loss: 8022818553856.0000 - val_mae: 1863021.2500\n",
            "Epoch 65/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5905153261568.0000 - mae: 1571632.2500 - val_loss: 8017769136128.0000 - val_mae: 1862398.0000\n",
            "Epoch 66/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8219448573952.0000 - mae: 1726691.3750 - val_loss: 8016490397696.0000 - val_mae: 1862240.6250\n",
            "Epoch 67/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8881132535808.0000 - mae: 1644275.6250 - val_loss: 8017553653760.0000 - val_mae: 1862382.2500\n",
            "Epoch 68/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6467790307328.0000 - mae: 1604433.8750 - val_loss: 8017223876608.0000 - val_mae: 1862344.7500\n",
            "Epoch 69/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8080897081344.0000 - mae: 1638623.3750 - val_loss: 8017901256704.0000 - val_mae: 1862435.6250\n",
            "Epoch 70/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7601621303296.0000 - mae: 1698007.3750 - val_loss: 8016348315648.0000 - val_mae: 1862244.0000\n",
            "Epoch 71/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5592645632000.0000 - mae: 1491106.7500 - val_loss: 8017581965312.0000 - val_mae: 1862406.2500\n",
            "Epoch 72/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6503972995072.0000 - mae: 1568159.0000 - val_loss: 8014497054720.0000 - val_mae: 1862017.3750\n",
            "Epoch 73/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8688315138048.0000 - mae: 1610975.5000 - val_loss: 8018174410752.0000 - val_mae: 1862489.7500\n",
            "Epoch 74/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8109048201216.0000 - mae: 1563153.5000 - val_loss: 8017005248512.0000 - val_mae: 1862348.6250\n",
            "Epoch 75/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 14308532551680.0000 - mae: 1929927.8750 - val_loss: 8018750078976.0000 - val_mae: 1862569.2500\n",
            "Epoch 76/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7637551284224.0000 - mae: 1667711.1250 - val_loss: 8016878895104.0000 - val_mae: 1862342.2500\n",
            "Epoch 77/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7683326869504.0000 - mae: 1708236.7500 - val_loss: 8015686139904.0000 - val_mae: 1862197.8750\n",
            "Epoch 78/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7234332393472.0000 - mae: 1596164.5000 - val_loss: 8013601046528.0000 - val_mae: 1861935.1250\n",
            "Epoch 79/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7828106379264.0000 - mae: 1707939.2500 - val_loss: 8015094218752.0000 - val_mae: 1862132.7500\n",
            "Epoch 80/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5489782423552.0000 - mae: 1468331.0000 - val_loss: 8013985349632.0000 - val_mae: 1861996.8750\n",
            "Epoch 81/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9440086458368.0000 - mae: 1780757.3750 - val_loss: 8014424178688.0000 - val_mae: 1862058.3750\n",
            "Epoch 82/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6681775833088.0000 - mae: 1600854.3750 - val_loss: 8011706793984.0000 - val_mae: 1861710.2500\n",
            "Epoch 83/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5038436515840.0000 - mae: 1412936.0000 - val_loss: 8016726851584.0000 - val_mae: 1862357.3750\n",
            "Epoch 84/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7000065835008.0000 - mae: 1622540.5000 - val_loss: 8013193674752.0000 - val_mae: 1861917.5000\n",
            "Epoch 85/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7898790363136.0000 - mae: 1666175.8750 - val_loss: 8013488324608.0000 - val_mae: 1861960.6250\n",
            "Epoch 86/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7549824270336.0000 - mae: 1548146.2500 - val_loss: 8012518391808.0000 - val_mae: 1861841.0000\n",
            "Epoch 87/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6535269318656.0000 - mae: 1617887.3750 - val_loss: 8011369152512.0000 - val_mae: 1861695.5000\n",
            "Epoch 88/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6518745858048.0000 - mae: 1551590.3750 - val_loss: 8012733874176.0000 - val_mae: 1861879.6250\n",
            "Epoch 89/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5825655472128.0000 - mae: 1548005.7500 - val_loss: 8014537424896.0000 - val_mae: 1862114.8750\n",
            "Epoch 90/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7683701211136.0000 - mae: 1724038.6250 - val_loss: 8012744359936.0000 - val_mae: 1861892.0000\n",
            "Epoch 91/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8533638119424.0000 - mae: 1695664.6250 - val_loss: 8015980789760.0000 - val_mae: 1862317.1250\n",
            "Epoch 92/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7682607546368.0000 - mae: 1659118.8750 - val_loss: 8010741579776.0000 - val_mae: 1861644.0000\n",
            "Epoch 93/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7283275202560.0000 - mae: 1709391.7500 - val_loss: 8013337853952.0000 - val_mae: 1861984.1250\n",
            "Epoch 94/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8410753925120.0000 - mae: 1729976.3750 - val_loss: 8013371932672.0000 - val_mae: 1861992.7500\n",
            "Epoch 95/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10304497909760.0000 - mae: 1721680.3750 - val_loss: 8012886441984.0000 - val_mae: 1861936.6250\n",
            "Epoch 96/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6430516051968.0000 - mae: 1632386.6250 - val_loss: 8013212549120.0000 - val_mae: 1861984.0000\n",
            "Epoch 97/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5469673881600.0000 - mae: 1552519.3750 - val_loss: 8012482740224.0000 - val_mae: 1861896.5000\n",
            "Epoch 98/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11669693530112.0000 - mae: 1826187.0000 - val_loss: 8013534461952.0000 - val_mae: 1862037.1250\n",
            "Epoch 99/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6906207272960.0000 - mae: 1593723.2500 - val_loss: 8012944113664.0000 - val_mae: 1861964.7500\n",
            "Epoch 100/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7499926208512.0000 - mae: 1666536.2500 - val_loss: 8012494798848.0000 - val_mae: 1861913.2500\n",
            "Epoch 101/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4639326470144.0000 - mae: 1518475.5000 - val_loss: 8010778279936.0000 - val_mae: 1861699.1250\n",
            "Epoch 102/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8932415242240.0000 - mae: 1752090.3750 - val_loss: 8009463889920.0000 - val_mae: 1861533.6250\n",
            "Epoch 103/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9694458413056.0000 - mae: 1769236.6250 - val_loss: 8010821271552.0000 - val_mae: 1861716.2500\n",
            "Epoch 104/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6081735032832.0000 - mae: 1547031.0000 - val_loss: 8009878601728.0000 - val_mae: 1861599.3750\n",
            "Epoch 105/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9483022499840.0000 - mae: 1783104.0000 - val_loss: 8010835951616.0000 - val_mae: 1861727.6250\n",
            "Epoch 106/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5871241265152.0000 - mae: 1544203.6250 - val_loss: 8011039375360.0000 - val_mae: 1861760.3750\n",
            "Epoch 107/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6700743000064.0000 - mae: 1569780.8750 - val_loss: 8011417387008.0000 - val_mae: 1861818.8750\n",
            "Epoch 108/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6471288356864.0000 - mae: 1610158.6250 - val_loss: 8012034473984.0000 - val_mae: 1861918.0000\n",
            "Epoch 109/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6970137378816.0000 - mae: 1624745.7500 - val_loss: 8010555457536.0000 - val_mae: 1861713.5000\n",
            "Epoch 110/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6249248194560.0000 - mae: 1627414.6250 - val_loss: 8011590402048.0000 - val_mae: 1861873.1250\n",
            "Epoch 111/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5438260117504.0000 - mae: 1525927.2500 - val_loss: 8009782132736.0000 - val_mae: 1861625.8750\n",
            "Epoch 112/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6933319254016.0000 - mae: 1627499.3750 - val_loss: 8009241591808.0000 - val_mae: 1861561.7500\n",
            "Epoch 113/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7595810095104.0000 - mae: 1670597.0000 - val_loss: 8010319003648.0000 - val_mae: 1861719.8750\n",
            "Epoch 114/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9531164721152.0000 - mae: 1688749.0000 - val_loss: 8011930664960.0000 - val_mae: 1861958.7500\n",
            "Epoch 115/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5876400259072.0000 - mae: 1584739.7500 - val_loss: 8010435395584.0000 - val_mae: 1861755.3750\n",
            "Epoch 116/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10155214241792.0000 - mae: 1689869.7500 - val_loss: 8009742286848.0000 - val_mae: 1861665.0000\n",
            "Epoch 117/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6664158183424.0000 - mae: 1621861.3750 - val_loss: 8012967706624.0000 - val_mae: 1862129.8750\n",
            "Epoch 118/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7145698885632.0000 - mae: 1582205.5000 - val_loss: 8009173434368.0000 - val_mae: 1861602.3750\n",
            "Epoch 119/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6985614360576.0000 - mae: 1632060.1250 - val_loss: 8007785119744.0000 - val_mae: 1861411.8750\n",
            "Epoch 120/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7295005622272.0000 - mae: 1638516.2500 - val_loss: 8007758381056.0000 - val_mae: 1861414.0000\n",
            "Epoch 121/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7952036003840.0000 - mae: 1651202.2500 - val_loss: 8007889977344.0000 - val_mae: 1861443.1250\n",
            "Epoch 122/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5891049390080.0000 - mae: 1467167.1250 - val_loss: 8007389806592.0000 - val_mae: 1861379.6250\n",
            "Epoch 123/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6792097038336.0000 - mae: 1597137.8750 - val_loss: 8009819357184.0000 - val_mae: 1861742.0000\n",
            "Epoch 124/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6848225738752.0000 - mae: 1606001.6250 - val_loss: 8011210293248.0000 - val_mae: 1861947.0000\n",
            "Epoch 125/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9803868930048.0000 - mae: 1760256.3750 - val_loss: 8009317089280.0000 - val_mae: 1861688.2500\n",
            "Epoch 126/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6252181061632.0000 - mae: 1477817.6250 - val_loss: 8008500772864.0000 - val_mae: 1861581.0000\n",
            "Epoch 127/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8069385814016.0000 - mae: 1668535.6250 - val_loss: 8007083622400.0000 - val_mae: 1861384.2500\n",
            "Epoch 128/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9745418158080.0000 - mae: 1655667.3750 - val_loss: 8007388233728.0000 - val_mae: 1861438.6250\n",
            "Epoch 129/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5923942170624.0000 - mae: 1458543.3750 - val_loss: 8007278657536.0000 - val_mae: 1861433.0000\n",
            "Epoch 130/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7876232347648.0000 - mae: 1638210.6250 - val_loss: 8006945734656.0000 - val_mae: 1861393.5000\n",
            "Epoch 131/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5617371054080.0000 - mae: 1449788.7500 - val_loss: 8006193381376.0000 - val_mae: 1861293.5000\n",
            "Epoch 132/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4969643114496.0000 - mae: 1480146.3750 - val_loss: 8005367103488.0000 - val_mae: 1861180.8750\n",
            "Epoch 133/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8502104817664.0000 - mae: 1723912.1250 - val_loss: 8005656510464.0000 - val_mae: 1861234.5000\n",
            "Epoch 134/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11987312443392.0000 - mae: 1894435.2500 - val_loss: 8005186748416.0000 - val_mae: 1861173.6250\n",
            "Epoch 135/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5497797738496.0000 - mae: 1516115.0000 - val_loss: 8007058980864.0000 - val_mae: 1861457.7500\n",
            "Epoch 136/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6182766379008.0000 - mae: 1499181.0000 - val_loss: 8005853118464.0000 - val_mae: 1861291.8750\n",
            "Epoch 137/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5372106506240.0000 - mae: 1504444.0000 - val_loss: 8003272572928.0000 - val_mae: 1860923.0000\n",
            "Epoch 138/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5891638689792.0000 - mae: 1522398.1250 - val_loss: 8005006917632.0000 - val_mae: 1861187.7500\n",
            "Epoch 139/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 10431178473472.0000 - mae: 1797129.2500 - val_loss: 8005620334592.0000 - val_mae: 1861288.1250\n",
            "Epoch 140/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6870586621952.0000 - mae: 1703730.8750 - val_loss: 8003738664960.0000 - val_mae: 1861019.6250\n",
            "Epoch 141/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6048323207168.0000 - mae: 1582896.0000 - val_loss: 8004707549184.0000 - val_mae: 1861173.8750\n",
            "Epoch 142/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4625288658944.0000 - mae: 1482225.7500 - val_loss: 8004739530752.0000 - val_mae: 1861188.7500\n",
            "Epoch 143/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6327309434880.0000 - mae: 1593152.5000 - val_loss: 8005611945984.0000 - val_mae: 1861325.7500\n",
            "Epoch 144/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6076589146112.0000 - mae: 1608036.3750 - val_loss: 8004558127104.0000 - val_mae: 1861182.2500\n",
            "Epoch 145/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4948760723456.0000 - mae: 1532353.3750 - val_loss: 8003440869376.0000 - val_mae: 1861027.7500\n",
            "Epoch 146/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8264219099136.0000 - mae: 1647055.3750 - val_loss: 8005525962752.0000 - val_mae: 1861342.8750\n",
            "Epoch 147/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6293516976128.0000 - mae: 1612367.0000 - val_loss: 8004557078528.0000 - val_mae: 1861211.0000\n",
            "Epoch 148/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6627587522560.0000 - mae: 1588281.7500 - val_loss: 8002958000128.0000 - val_mae: 1860984.8750\n",
            "Epoch 149/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7749274435584.0000 - mae: 1694219.0000 - val_loss: 8005902925824.0000 - val_mae: 1861423.3750\n",
            "Epoch 150/150\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7594172219392.0000 - mae: 1587700.5000 - val_loss: 8002655485952.0000 - val_mae: 1860960.8750\n",
            "CPU times: total: 3min 13s\n",
            "Wall time: 2min 21s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x41e221ee70>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "num_epochs = 150\n",
        "model.fit(x, y, epochs=num_epochs, batch_size=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3420000</td>\n",
              "      <td>3354425.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10500000</td>\n",
              "      <td>8265430.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5000000</td>\n",
              "      <td>5981242.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3600000</td>\n",
              "      <td>3823953.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5950000</td>\n",
              "      <td>7757833.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>6300000</td>\n",
              "      <td>9267935.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>10000000</td>\n",
              "      <td>8899927.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>4100000</td>\n",
              "      <td>4458450.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>3600000</td>\n",
              "      <td>2783378.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>7500000</td>\n",
              "      <td>6869537.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>706 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         true       pred\n",
              "0     3420000  3354425.5\n",
              "1    10500000  8265430.5\n",
              "2     5000000  5981242.5\n",
              "3     3600000  3823953.5\n",
              "4     5950000  7757833.5\n",
              "..        ...        ...\n",
              "701   6300000  9267935.0\n",
              "702  10000000  8899927.0\n",
              "703   4100000  4458450.5\n",
              "704   3600000  2783378.5\n",
              "705   7500000  6869537.5\n",
              "\n",
              "[706 rows x 2 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({'true': np.squeeze(y), 'pred': np.squeeze(model.predict(x))})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('price_model.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
